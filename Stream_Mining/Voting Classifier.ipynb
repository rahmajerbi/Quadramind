{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,f1_score\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           DATETIME    RR   SPO2   MAP   SBP   DBP     HR    PP       CO  \\\n",
      "0  2020-10-18 15:24  35.0   99.9   0.0   0.0   0.0  106.9   0.0     0.00   \n",
      "1  2020-10-18 15:25  36.4  100.0  87.0  98.9  63.1  107.3  35.8  3841.34   \n",
      "2  2020-10-18 15:26  35.2  100.0  75.2  97.9  63.0  107.5  34.9  3751.75   \n",
      "3  2020-10-18 15:27  34.0  100.0  74.8  97.2  62.5  107.0  34.7  3712.90   \n",
      "4  2020-10-18 15:28  34.9  100.0  74.0  96.0  62.0  107.0  34.0  3638.00   \n",
      "\n",
      "   Classes  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./historical_data.csv\")\n",
    "df['Classes'] = df['Class'].apply(lambda x: 'Normal' if x == 'Normal' else 'High')\n",
    "# Map 'Normal' to 1 and 'High' to 0\n",
    "df['Classes'] = df['Class'].apply(lambda x: 0 if x == 'Normal' else 1)\n",
    "\n",
    "# Drop the original 'Class' column\n",
    "df = df.drop(columns=['Class'])\n",
    "\n",
    "# Verify the changes\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding target column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['DATETIME', 'Classes'], axis=1) \n",
    "y = df['Classes'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train=pd.DataFrame(X_train, index=X_train.index)\n",
    "X_test=pd.DataFrame(X_test, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembled Classifier:XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.5, 'gamma': 0.2, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1}\n",
      "Accuracy: 0.9994453688297282\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1780\n",
      "           1       0.96      1.00      0.98        23\n",
      "\n",
      "    accuracy                           1.00      1803\n",
      "   macro avg       0.98      1.00      0.99      1803\n",
      "weighted avg       1.00      1.00      1.00      1803\n",
      "\n",
      "Train F1_Score:  1.0\n",
      "Val F1_Score:  0.9994453688297282\n"
     ]
    }
   ],
   "source": [
    "model_xgb= xgb.XGBClassifier(random_state=42,verbosity=0, min_child_weight=2,\n",
    "                             max_depth=4, learning_rate=0.15, gamma=0.22, colsample_bytree=0.5)\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.15, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_child_weight': [1, 2, 3],\n",
    "    'gamma': [0.2, 0.3, 0.4],\n",
    "    'colsample_bytree': [0.5, 0.6, 0.7]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model_xgb, param_grid, scoring='accuracy', cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_model_xgb = grid_search.best_estimator_\n",
    "best_model_xgb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = best_model_xgb.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Train F1_Score: \", metrics.f1_score(y_train, best_model_xgb.predict(X_train), average='micro'))\n",
    "print(\"Val F1_Score: \", metrics.f1_score(y_test, best_model_xgb.predict(X_test), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9988907376594565\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1780\n",
      "           1       1.00      0.91      0.95        23\n",
      "\n",
      "    accuracy                           1.00      1803\n",
      "   macro avg       1.00      0.96      0.98      1803\n",
      "weighted avg       1.00      1.00      1.00      1803\n",
      "\n",
      "Train F1_Score:  0.9991678224687933\n",
      "Val F1_Score:  0.9988907376594565\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define a reduced search space\n",
    "param_dist = {\n",
    "    'C': [1, 10, 25],\n",
    "    'gamma': ['scale', 'auto', 1e-3],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "# Create the SVM model\n",
    "model_svc = SVC(probability=True)\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(model_svc, param_dist, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Access the best model from the random search\n",
    "best_model_svc = random_search.best_estimator_\n",
    "best_model_svc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model_svc.predict(X_test)\n",
    "\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Train F1_Score: \", metrics.f1_score(y_train, best_model_svc.predict(X_train), average='micro'))\n",
    "print(\"Val F1_Score: \", metrics.f1_score(y_test, best_model_svc.predict(X_test), average='micro'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Naive Bayes): 0.9900166389351082\n",
      "Classification Report (Naive Bayes):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1780\n",
      "           1       0.58      0.83      0.68        23\n",
      "\n",
      "    accuracy                           0.99      1803\n",
      "   macro avg       0.79      0.91      0.84      1803\n",
      "weighted avg       0.99      0.99      0.99      1803\n",
      "\n",
      "F1 Score (Naive Bayes): 0.9900166389351082\n"
     ]
    }
   ],
   "source": [
    "# Define a search space for hyperparameter tuning\n",
    "param_dist = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "}\n",
    "\n",
    "# Create the Naive Bayes model\n",
    "model_nb = GaussianNB()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "random_search_nb = RandomizedSearchCV(model_nb, param_dist, n_iter=5, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search_nb.fit(X_train, y_train)\n",
    "\n",
    "# Access the best model from the random search\n",
    "best_model_nb = random_search_nb.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_nb = best_model_nb.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(\"Accuracy (Naive Bayes):\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Classification Report (Naive Bayes):\\n\", classification_report(y_test, y_pred_nb))\n",
    "print(\"F1 Score (Naive Bayes):\", f1_score(y_test, y_pred_nb, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9988907376594565\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1780\n",
      "           1       1.00      0.91      0.95        23\n",
      "\n",
      "    accuracy                           1.00      1803\n",
      "   macro avg       1.00      0.96      0.98      1803\n",
      "weighted avg       1.00      1.00      1.00      1803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the DecisionTreeClassifier\n",
    "model_dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "grid_search = GridSearchCV(model_dt, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Access the best model from the grid search\n",
    "best_model_dt = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_dt = best_model_dt.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best Accuracy: 0.9918169209431346\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a KNN classifier\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],  # Adjust as needed\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan'] \n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(knn_model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Use the best model for predictions\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "y_pred = best_knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score:  1.0\n",
      "XGBClassifier 0.9994453688297282\n",
      "SVC 0.9988907376594565\n",
      "GaussianNB 0.9900166389351082\n",
      "DecisionTreeClassifier 1.0\n",
      "KNeighborsClassifier 0.9933444259567388\n"
     ]
    }
   ],
   "source": [
    "voting_model = VotingClassifier(estimators=[('XGBoost', best_model_xgb), ('SVMClassifier',\n",
    "                                                                           best_model_svc),('GaussianNB', best_model_nb),\n",
    "                                            ('DecisionTreeClassifier', best_model_dt), ('KnnClassifier', best_knn_model)\n",
    "                                           ], voting='soft')\n",
    "\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"F1_Score: \", metrics.f1_score(y_test, voting_model.predict(X_test), average='micro'))\n",
    "for clf in (best_model_xgb, best_model_svc, best_model_nb, best_model_dt,best_knn_model):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, metrics.f1_score(y_test, y_pred, average='micro'))\n",
    "\n",
    "y_test_pred = voting_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1780    0]\n",
      " [   0   23]]\n",
      "F1_Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Print F1 score for the ensemble model\n",
    "print(\"F1_Score: \", metrics.f1_score(y_test,y_test_pred, average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v_model.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "# Save the ensemble model as a pickle file\n",
    "joblib.dump(voting_model, 'v_model.pkl')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
