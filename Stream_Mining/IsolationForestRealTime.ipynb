{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from confluent_kafka import Consumer, KafkaError\n",
    "from json import loads\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Suppress sklearn warning about missing feature names\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names, but IsolationForest\")\n",
    "\n",
    "import numpy as np  # Import NumPy for array manipulation\n",
    "# Reading messages from the consumer with a 5-second interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Load the saved model\n",
    "loaded_model = joblib.load('isolation_forest_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kafka broker address\n",
    "bootstrap_servers = 'localhost:9093'\n",
    " \n",
    "# Kafka topic to consume messages from\n",
    "kafka_topic = 'Topic_test'\n",
    " \n",
    "# # Consumer group ID\n",
    "# group_id = 'group1'\n",
    " \n",
    "# InfluxDB connection details\n",
    "influxdb_host = 'localhost'\n",
    "influxdb_port = 8086\n",
    "influxdb_username = 'mahirasadzade'\n",
    "influxdb_password = 'mahira123'\n",
    "bucket = \"BloodPressure\"\n",
    "organization = \"OstProject\"\n",
    "influxdb_token = \"DG2B6mm_vDI_4oVm9OW3pCiv1A6ID5Jr9XGgn_7uIbG8iElhhzwYOOXw5Begzk3fTI9M1nh-XI6Qb2qA1k7RIg==\"\n",
    "\n",
    "# Create Kafka consumer configuration\n",
    "consumer_config = {\n",
    "    'bootstrap.servers': bootstrap_servers,\n",
    "    # 'group.id': group_id,\n",
    "    'auto.offset.reset': 'earliest'\n",
    "}\n",
    " \n",
    "with InfluxDBClient(url=\"http://localhost:8086\", token=influxdb_token, org=organization,bucket=bucket) as client:\n",
    "        write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "        consumer = KafkaConsumer(kafka_topic, bootstrap_servers=['localhost:9093'],auto_offset_reset='earliest', api_version=(0,10),enable_auto_commit=True,value_deserializer=lambda x: loads(x.decode('utf-8')))\n",
    "        print(\"Connection established\")\n",
    "        i=0\n",
    "        for message in consumer:\n",
    "            print(f\"{message.value}\")\n",
    "            # Reshape the input data into a 2D array\n",
    "            sbp = np.array(message.value.get('SBP')).reshape(-1, 1)\n",
    "            dbp = np.array(message.value.get('DBP')).reshape(-1, 1)\n",
    "            hr = np.array(message.value.get('HR')).reshape(-1, 1)\n",
    "            rr = np.array(message.value.get('RR')).reshape(-1, 1)\n",
    "            co = np.array(message.value.get('CO')).reshape(-1, 1)\n",
    "\n",
    "            # Use the loaded model for prediction\n",
    "            score = loaded_model.decision_function(np.concatenate((sbp, dbp), axis=1))[0]\n",
    "            anomaly_value = loaded_model.predict(np.concatenate((sbp, dbp), axis=1))[0]\n",
    "            # Detect anomalies based on the threshold\n",
    "            detection = 1 if anomaly_value == -1 else 0\n",
    "            label = \"Normal\" if anomaly_value == -1 else \"Anormal\"\n",
    "            #print(sbp[0][0], dbp[0][0], detection)\n",
    "            row_count = 1\n",
    "             # Create InfluxDB point\n",
    "            point = Point(\"IsolationForestv4\") \\\n",
    "                    .field(\"Detection\", int(detection)) \\\n",
    "                    .field(\"Label\", label) \\\n",
    "                    .field(\"SBP\", float(sbp[0][0])) \\\n",
    "                    .field(\"DBP\", float(dbp[0][0])) \\\n",
    "                    .field(\"HR\", float(hr[0][0])) \\\n",
    "                    .field(\"RR\", float(rr[0][0])) \\\n",
    "                    .field(\"CO\", float(co[0][0])) \\\n",
    "                    .field(\"All records\", row_count) \\\n",
    "                    .field(\"AnomalyScore\", score)\n",
    "                   \n",
    "            print(point)\n",
    "            # Print the table\n",
    "            from tabulate import tabulate\n",
    "            table = [[\"SBP\", \"DBP\", \"Anomaly Score\", \"Anomaly\"],\n",
    "                             [sbp, dbp, score, detection]]\n",
    "            print(tabulate(table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "            \n",
    "            # Write the point to InfluxDB\n",
    "            write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "            write_api.write(bucket, organization, point)\n",
    "            \n",
    "            i+=1\n",
    "            print(\"Message sent to influxDB\", i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
